{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18549,"status":"ok","timestamp":1686179394126,"user":{"displayName":"RICHARD KHILLAH","userId":"00618221559280530485"},"user_tz":420},"id":"alQJzStM1OEO","outputId":"5f0f92da-b261-40ca-dec9-975b5fc625cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDupWFQc176c"},"outputs":[],"source":["sys.path += ['/content/drive/Shareddrive/filtered_data']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BWYwEIsyPXv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":524,"status":"ok","timestamp":1686179399900,"user":{"displayName":"RICHARD KHILLAH","userId":"00618221559280530485"},"user_tz":420},"id":"edmY_7ZIySrX","outputId":"d2a10835-9470-4f43-9ff2-83545aca87b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/cs145project/filtered_data/stocks\n"]}],"source":["%cd /content/drive/Shareddrives/cs145project/filtered_data/stocks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1565,"status":"ok","timestamp":1686179402520,"user":{"displayName":"RICHARD KHILLAH","userId":"00618221559280530485"},"user_tz":420},"id":"fVygqa0AyTXu","outputId":"beafd780-b26a-478b-f2af-f6ca03face1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["dish 2009-08-11 $18.53\n","agn 2009-08-13 $34.45\n","hd 2009-08-10 $27.10\n","mu 2011-04-19 $10.52\n","bmy 2009-08-13 $21.86\n"]}],"source":["def parse_stock_name(filename, lower=True):\n","  sym = filename.split('-')[0]\n","  return sym.lower() if lower else sym\n","\n","for file in os.listdir()[:5]:\n","  stock_df = pd.read_csv(file)\n","  print(f\"{parse_stock_name(file)} {stock_df['Date'][0]} ${stock_df['Close'][0]:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YeejfzaeyDwq"},"outputs":[],"source":["import os\n","import pickle\n","import stat\n","import time\n","\n","pickle_path = '/content/drive/Shareddrives/cs145project/pickles'\n","\n","names = {\n","      'sgd': 'sgd_model.pickle',\n","      'spacy': 'spacy_model.pickle',\n","      'bert': 'bert_model.pickle',\n","      'neural': 'nn_model.pickle',\n","      'data_train': 'data_train.pickle',\n","      'best_nn_model': 'best_nn_model.pickle',\n","  }\n","\n","def pickle_obj(obj, name, overwrite=False):\n","  \"\"\" Cache an object registered in the names dictionary above.\n","\n","  @obj  The object you want to cache\n","  @name Key into the names dictionary above.\n","  @overwrite  Overwrite a previously saved version of the pickle. If false and\n","              a file exists, user is promted whether to continue. Upon 'y',\n","              overwrite is set to 'True' and the previos file is overwritten.\n","  \"\"\"\n","  # if a file exists and not overwrite, ask for user input to force overwrite.\n","  try:\n","    save_path = os.path.join(pickle_path, names[name])\n","  except KeyError as ke:\n","    raise KeyError(f\"'{name}' is not a supported object name. Supported objects are:\\n\"\n","                   f\"{names.keys()}\")\n","\n","  conflict_cond = os.path.exists(save_path) and not overwrite\n","  if conflict_cond:\n","    # get user input to continue, and proceed only on 'y'\n","    print(f\"A previous pickle for '{name}' was found.\")\n","    print(f\"{save_path}\")\n","    while True:\n","      _overwrite = input(\"Would you like to overwrite? (y/n): \").lower()\n","      if _overwrite not in ['y', 'n']:\n","        print(\"Invalid response.\")\n","        continue\n","      else:\n","        overwrite = True if _overwrite == 'y' else False\n","        break\n","\n","  if overwrite:\n","    print(f\"Overwriting '{save_path}' object\")\n","  elif conflict_cond:\n","    print(f\"Not pickling '{name}' object\")\n","\n","  if overwrite or not conflict_cond:\n","    with open(save_path, 'wb') as fd:\n","      print(f\"pickling '{name}' model...\", end=\"\")\n","      pickle.dump(obj, fd)\n","      print(f\"done. Saved '{name}' model to {save_path}\")\n","\n","def unpickle_obj(name):\n","  try:\n","    load_path = os.path.join(pickle_path, names[name])\n","  except KeyError as ke:\n","    raise KeyError(f\"'{name}' is not a supported object name. Supported objects are:\\n\"\n","                   f\"{names.keys()}\")\n","  try:\n","    with open(load_path, 'rb') as fd:\n","      return pickle.load(fd)\n","  except FileNotFoundError as err:\n","    raise FileNotFoundError(f\"No pickled file for '{name}' found.\\n\"\n","                            f\"{err}\")"]},{"cell_type":"markdown","metadata":{"id":"AfAoCOB6atXw"},"source":["## Training the headline classifier\n","Here, I'm going to take the headline sentiments data set we have, and train a text classifier to determine if a headline is positive, negative, or neutral."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3334,"status":"ok","timestamp":1686179411437,"user":{"displayName":"RICHARD KHILLAH","userId":"00618221559280530485"},"user_tz":420},"id":"Bsfg1XK4SwnL","outputId":"d86dcb7b-20a7-412c-9f4a-5f0dfb41760d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import SGDClassifier\n","\n","import six\n","import sys\n","sys.modules['sklearn.externals.six'] = six\n","from mlxtend.classifier import EnsembleVoteClassifier\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686141947130,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"a2DoC8q_lzk_","outputId":"ec4ddcea-b12a-461f-fc22-70b73f3524d1"},"outputs":[{"data":{"text/plain":["1116                 wellness services important future .\n","3838    equipment made vaahto 's plant hollola finland...\n","4324    juhani j+Ã¦rvi , corporate executive vice presi...\n","2776    transaction , m-real 30 % metsa-botnia upm -- ...\n","1887         `` pleased welcome tapeks noma cramo group .\n","                              ...                        \n","1033    construction scheduled start april-june 2007 c...\n","3264    gypsii mobile social networking application av...\n","1653    service intended allow people thirteen mediter...\n","2607                   company website www.ahlstrom.com .\n","2732    employees would remain oulu plant support func...\n","Name: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing ., Length: 3876, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1686141947405,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"WPnuKtnQar3s","outputId":"ed43c608-42bd-45a9-835b-912c17ad3e05"},"outputs":[{"name":"stdout","output_type":"stream","text":["train accuracy: 0.9780701754385965\n","test accuracy: 0.7492260061919505\n"]}],"source":["# Model building\n","model = make_pipeline(TfidfVectorizer(), SGDClassifier())\n","# Training the model with the training data\n","model.fit(X_train, y_train)\n","\n","# Training accuracy\n","predicted_train = model.predict(X_train)\n","print(f\"train accuracy: {accuracy_score(y_train, predicted_train)}\")\n","\n","# Predicting the test data categories\n","predicted_categories = model.predict(X_test)\n","print(f\"test accuracy: {accuracy_score(y_test, predicted_categories)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgRTgCM6ynpu"},"outputs":[],"source":["# pickle_obj(model, 'sgd')"]},{"cell_type":"markdown","metadata":{"id":"BV98Sy6SSOYv"},"source":["## TO DO: Classifying Headlines\n","In this section, we will take our trained classifier and use it to classify headlines of the 50 stocks within our Headlines dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686141947406,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"rBSFNzGpStvR","outputId":"9cbc7a22-7226-409a-9f44-0f649d7f3320"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Shareddrives/cs145project/filtered_data\n"]}],"source":["# Change Directories Again\n","%cd /content/drive/Shareddrives/cs145project/filtered_data/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":765,"status":"ok","timestamp":1686141948169,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"PydKtAebUoxe","outputId":"dff16a1d-1bcd-488b-8220-a720409bc890"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e40f0726-0ee8-40bd-9bfd-3ffef332e6b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>date</th>\n","      <th>stock</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>piper sandler maintains overweight adobe, lowe...</td>\n","      <td>2020-03-31 06:18:00-04:00</td>\n","      <td>ADBE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>shares several technology companies trading hi...</td>\n","      <td>2020-03-30 10:23:00-04:00</td>\n","      <td>ADBE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>shares several technology, semiconductor softw...</td>\n","      <td>2020-03-27 11:30:00-04:00</td>\n","      <td>ADBE</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cramer reveals stock favorites, says intuitive...</td>\n","      <td>2020-03-27 10:10:00-04:00</td>\n","      <td>ADBE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>shares several software companies trading high...</td>\n","      <td>2020-03-26 10:38:00-04:00</td>\n","      <td>ADBE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e40f0726-0ee8-40bd-9bfd-3ffef332e6b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e40f0726-0ee8-40bd-9bfd-3ffef332e6b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e40f0726-0ee8-40bd-9bfd-3ffef332e6b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  \\\n","0  piper sandler maintains overweight adobe, lowe...   \n","1  shares several technology companies trading hi...   \n","2  shares several technology, semiconductor softw...   \n","3  cramer reveals stock favorites, says intuitive...   \n","4  shares several software companies trading high...   \n","\n","                        date stock  \n","0  2020-03-31 06:18:00-04:00  ADBE  \n","1  2020-03-30 10:23:00-04:00  ADBE  \n","2  2020-03-27 11:30:00-04:00  ADBE  \n","3  2020-03-27 10:10:00-04:00  ADBE  \n","4  2020-03-26 10:38:00-04:00  ADBE  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["path=\"top-50-analyst-ratings-processed.csv\"\n","headlines=pd.read_csv(path,encoding = \"ISO-8859-1\")\n","headlines['title']=headlines['title'].apply(clean_text)\n","headlines.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":1252,"status":"ok","timestamp":1686141949419,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"sxInpgeHVGCX","outputId":"6e163d20-9f3c-4c44-dab6-557612d9931b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment Distribution:\n","    Sentiment\tcount\t% of dataset\n","    neutral\t87940\t75.167%\n","    positive\t20751\t17.737%\n","    negative\t8302\t7.096%\n"]},{"data":{"text/html":["\n","  <div id=\"df-24e8c879-1bf5-4a0f-92d9-3b9412b92d4a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>date</th>\n","      <th>stock</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>piper sandler maintains overweight adobe, lowe...</td>\n","      <td>2020-03-31 06:18:00-04:00</td>\n","      <td>ADBE</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>shares several technology companies trading hi...</td>\n","      <td>2020-03-30 10:23:00-04:00</td>\n","      <td>ADBE</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>shares several technology, semiconductor softw...</td>\n","      <td>2020-03-27 11:30:00-04:00</td>\n","      <td>ADBE</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cramer reveals stock favorites, says intuitive...</td>\n","      <td>2020-03-27 10:10:00-04:00</td>\n","      <td>ADBE</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>shares several software companies trading high...</td>\n","      <td>2020-03-26 10:38:00-04:00</td>\n","      <td>ADBE</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24e8c879-1bf5-4a0f-92d9-3b9412b92d4a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-24e8c879-1bf5-4a0f-92d9-3b9412b92d4a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-24e8c879-1bf5-4a0f-92d9-3b9412b92d4a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  \\\n","0  piper sandler maintains overweight adobe, lowe...   \n","1  shares several technology companies trading hi...   \n","2  shares several technology, semiconductor softw...   \n","3  cramer reveals stock favorites, says intuitive...   \n","4  shares several software companies trading high...   \n","\n","                        date stock sentiment  \n","0  2020-03-31 06:18:00-04:00  ADBE   neutral  \n","1  2020-03-30 10:23:00-04:00  ADBE  positive  \n","2  2020-03-27 11:30:00-04:00  ADBE  positive  \n","3  2020-03-27 10:10:00-04:00  ADBE   neutral  \n","4  2020-03-26 10:38:00-04:00  ADBE   neutral  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["input=headlines['title']\n","cats=model.predict(input)\n","headlines['sentiment']=cats\n","\n","from collections import Counter\n","counts = Counter(headlines['sentiment'])\n","print(\"Sentiment Distribution:\")\n","print(\"    Sentiment\\tcount\\t% of dataset\")\n","for sentiment, count in counts.items():\n","  print(f\"    {sentiment}\\t{count}\\t{((count/counts.total())*100):.3f}%\")\n","\n","headlines.head()"]},{"cell_type":"markdown","metadata":{"id":"qsl43DBoErUX"},"source":["# Transform datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686141949419,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"z5pWmKW7Exvq","outputId":"739197e2-4267-4d7f-b484-765d78033b54"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Shareddrives/cs145project/split_data\n"]}],"source":["sys.path.extend(['/content/drive/Shareddrives/cs145project/code', '/content/drive/Shareddrives/cs145project'])\n","\n","%cd /content/drive/Shareddrives/cs145project/split_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plqOiWrUOhTz"},"outputs":[],"source":["majority_pickle_path = '/content/drive/Shareddrives/cs145project/filtered_data/majority_vote_sentiment.pkl'\n","\n","majority_df = pd.read_pickle(majority_pickle_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysGnnPRmxZam"},"outputs":[],"source":["def get_predictions(df):\n","  return majority_df.loc[majority_df['title'].isin(df['title']) & majority_df['stock'].isin(df['stock'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":542,"status":"ok","timestamp":1686141950847,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"AoCNf0pPg0i0","outputId":"92d7941d-c49a-465e-9b33-233a86c4f768"},"outputs":[{"data":{"text/plain":["10       neutral\n","14      negative\n","15      negative\n","16       neutral\n","17       neutral\n","          ...   \n","1969     neutral\n","1970     neutral\n","1971     neutral\n","1972     neutral\n","1973     neutral\n","Name: sentiment, Length: 1939, dtype: object"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["news = \"train_news/ADBE-analyst-rating-train.csv\"\n","news_df = pd.read_csv(news)\n","prediction_test = get_predictions(news_df)[\"sentiment\"]\n","prediction_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_5e0YM-GfC7"},"outputs":[],"source":["\n","from collections import Counter\n","\n","def make_filenames_dict(dir):\n","  return {parse_stock_name(f).lower(): os.path.join('.', dir, f) for f in os.listdir(os.path.join('.', dir))}\n","\n","def load_data(filename):\n","  return pd.read_csv(filename, encoding = \"ISO-8859-1\")"]},{"cell_type":"markdown","metadata":{"id":"NRlthoZylk7q"},"source":["# Data Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686141950848,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"K4cfW60bzo6g","outputId":"db06bc04-18d0-4dbc-9f59-c5a9a6deb961"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/Shareddrives/cs145project/split_data\n"]}],"source":["%cd /content/drive/Shareddrives/cs145project/split_data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHvUvYUo1NQR"},"outputs":[],"source":["# Process SPY DF for Data Engineering\n","def process_spy(spy_path):\n","  df = pd.read_csv(spy_path)\n","  df[\"spy1daydiff\"] = df[\"Close\"].diff(1) / df[\"Close\"].shift(1)\n","  df[\"spy2daydiff\"] = df[\"Close\"].diff(2) / df[\"Close\"].shift(2)\n","  df[\"spy3daydiff\"] = df[\"Close\"].diff(3) / df[\"Close\"].shift(3)\n","  df[\"spy4daydiff\"] = df[\"Close\"].diff(4) / df[\"Close\"].shift(4)\n","  df[\"spy5daydiff\"] = df[\"Close\"].diff(5) / df[\"Close\"].shift(5)\n","  df[\"spy10daydiff\"] = df[\"Close\"].diff(10) / df[\"Close\"].shift(10)\n","  df[\"spy20daydiff\"] = df[\"Close\"].diff(20) / df[\"Close\"].shift(20)\n","  df[\"spy30daydiff\"] = df[\"Close\"].diff(30) / df[\"Close\"].shift(30)\n","\n","  df = df.drop(columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"])\n","  df = df.dropna()\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKCFZV3rMW6i"},"outputs":[],"source":["from nltk.corpus.reader.mte import xpath\n","\n","# Combine given stock, news, and spy DFs into one merged DF\n","def combine_stock_news(stock, news, spy):\n","  stock = stock\n","  news = news\n","\n","\n","  # Drop Label\n","  stock = stock.drop('label', axis=1)\n","\n","  # Create label for row a: (x[a+1] - x[a]) / x[a]\n","  stock[\"label\"] = (stock[\"Close\"].shift(-1) - stock[\"Close\"]) / stock[\"Close\"]\n","\n","  # Create % price shifts across days\n","  stock[\"1daydiff\"] = stock[\"Close\"].diff(1) / stock[\"Close\"].shift(1)\n","  stock[\"2daydiff\"] = stock[\"Close\"].diff(2) / stock[\"Close\"].shift(2)\n","  stock[\"3daydiff\"] = stock[\"Close\"].diff(3) / stock[\"Close\"].shift(3)\n","  stock[\"4daydiff\"] = stock[\"Close\"].diff(4) / stock[\"Close\"].shift(4)\n","  stock[\"5daydiff\"] = stock[\"Close\"].diff(5) / stock[\"Close\"].shift(5)\n","  stock[\"10daydiff\"] = stock[\"Close\"].diff(10) / stock[\"Close\"].shift(10)\n","  stock[\"20daydiff\"] = stock[\"Close\"].diff(20) / stock[\"Close\"].shift(20)\n","  stock[\"30daydiff\"] = stock[\"Close\"].diff(30) / stock[\"Close\"].shift(30)\n","  stock = stock.dropna()\n","\n","\n","  # Merge with S&P to create 5 days percent change compared to market\n","\n","  stock = stock.merge(spy, on=\"Date\", how=\"left\")\n","  stock[\"spy1daydiff\"] = stock[\"1daydiff\"] - stock[\"spy1daydiff\"]\n","  stock[\"spy2daydiff\"] = stock[\"2daydiff\"] - stock[\"spy2daydiff\"]\n","  stock[\"spy3daydiff\"] = stock[\"3daydiff\"] - stock[\"spy3daydiff\"]\n","  stock[\"spy4daydiff\"] = stock[\"4daydiff\"] - stock[\"spy4daydiff\"]\n","  stock[\"spy5daydiff\"] = stock[\"5daydiff\"] - stock[\"spy5daydiff\"]\n","  stock[\"spy10daydiff\"] = stock[\"10daydiff\"] - stock[\"spy10daydiff\"]\n","  stock[\"spy20daydiff\"] = stock[\"20daydiff\"] - stock[\"spy20daydiff\"]\n","  stock[\"spy30daydiff\"] = stock[\"30daydiff\"] - stock[\"spy30daydiff\"]\n","\n","\n","  # Categorize label into +1, 0, -1 based on % change from yesterday\n","  stock['label'] = stock['label'].apply(lambda x: 1 if x > 0.005 else (-1 if x < -0.005 else 0))\n","\n","  news['sentiment'] = get_predictions(news)[\"sentiment\"]\n","\n","  # Group by 'Date' and 'Sentiment', and aggregate counts\n","  news = news.groupby(['date', 'sentiment']).size().reset_index(name='Count')\n","\n","  # Pivot the table to have sentiment types as separate columns\n","  news = news.pivot_table(index='date', columns='sentiment', values='Count', fill_value=0).reset_index()\n","\n","  # Perform left merge on stock and news based on date\n","  df_merged = stock.merge(news, left_on=\"Date\", right_on=\"date\", how=\"left\")\n","  df_merged = df_merged.fillna(0)\n","\n","  df_merged = df_merged.drop(columns=[\"date\", \"Adj Close\", \"Date\"])\n","\n","  # Drops first 30 + last 1 rows\n","  return df_merged"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6HzWQMnFAZ4"},"outputs":[],"source":["# Process and combine datasets from 50 companies into 1 DF for training\n","def combine_datasets():\n","\n","  # Generate file paths\n","  train_stock_files = make_filenames_dict(\"train_stock\")\n","  train_news_files = make_filenames_dict(\"train_news\")\n","  test_stock_files = make_filenames_dict(\"test_stock\")\n","  test_news_files = make_filenames_dict(\"test_news\")\n","  SPY_PATH = \"SPY.csv\"\n","\n","  df = pd.DataFrame()\n","\n","  spy = process_spy(SPY_PATH)\n","\n","  for stock in train_stock_files.keys():\n","    # Get file paths for stock\n","    train_stock = pd.read_csv(train_stock_files[stock])\n","    train_news = pd.read_csv(train_news_files[stock])\n","    test_stock = pd.read_csv(test_stock_files[stock])\n","    test_news = pd.read_csv(test_news_files[stock])\n","\n","    # Merge train and test DFs\n","    stock_df = pd.concat([train_stock, test_stock], ignore_index=True)\n","    news_df = pd.concat([train_news, test_news], ignore_index=True)\n","\n","    # Data engineer for stock and get DF\n","    df_new = combine_stock_news(stock = stock_df, news = news_df, spy=spy)\n","\n","    # Merge train and test into main DF\n","    df = pd.concat([df, df_new], ignore_index=True)\n","    print(f\"Merged stock: {stock} with shape={df_new.shape} made from {train_stock.shape} and {test_stock.shape}\")\n","\n","  # Fill 0 since some dfs are missing sentiment columns and got autofilled to NaN in the concat\n","  df = df.fillna(0)\n","\n","  print(f\"Finished merged dataset with shape: {df.shape}\")\n","\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":64957,"status":"ok","timestamp":1686142016051,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"gjTaniNZEx-c","outputId":"2ee49e70-e0cc-485b-f536-239e54f79204"},"outputs":[{"name":"stdout","output_type":"stream","text":["Merged stock: azn with shape=(2644, 22) made from (2664, 8) and (11, 8)\n","Merged stock: pep with shape=(2644, 22) made from (2664, 8) and (11, 8)\n","Merged stock: tm with shape=(2633, 22) made from (2673, 8) and (11, 8)\n","Merged stock: mrk with shape=(2659, 22) made from (2679, 8) and (11, 8)\n","Merged stock: grpn with shape=(2083, 22) made from (2103, 8) and (11, 8)\n","Merged stock: fcx with shape=(2649, 22) made from (2669, 8) and (11, 8)\n","Merged stock: atvi with shape=(2639, 22) made from (2659, 8) and (11, 8)\n","Merged stock: ms with shape=(2529, 22) made from (2559, 8) and (11, 8)\n","Merged stock: baba with shape=(1202, 22) made from (1222, 8) and (11, 8)\n","Merged stock: bmy with shape=(2646, 22) made from (2667, 8) and (11, 8)\n","Merged stock: adbe with shape=(2644, 25) made from (2664, 8) and (11, 8)\n","Merged stock: dish with shape=(2648, 22) made from (2668, 8) and (11, 8)\n","Merged stock: gild with shape=(2644, 22) made from (2664, 8) and (11, 8)\n","Merged stock: nok with shape=(2649, 22) made from (2669, 8) and (11, 8)\n","Merged stock: cmg with shape=(1781, 22) made from (1801, 8) and (11, 8)\n","Merged stock: biib with shape=(2180, 22) made from (2200, 8) and (11, 8)\n","Merged stock: chk with shape=(2619, 22) made from (2639, 8) and (11, 8)\n","Merged stock: lly with shape=(2644, 22) made from (2664, 8) and (11, 8)\n","Merged stock: myl with shape=(2600, 22) made from (2620, 8) and (11, 8)\n","Merged stock: jnj with shape=(2185, 22) made from (2205, 8) and (11, 8)\n","Merged stock: lmt with shape=(2475, 22) made from (2495, 8) and (11, 8)\n","Merged stock: nvda with shape=(2256, 22) made from (2276, 8) and (11, 8)\n","Merged stock: nflx with shape=(878, 22) made from (898, 8) and (11, 8)\n","Merged stock: gpro with shape=(1410, 22) made from (1430, 8) and (11, 8)\n","Merged stock: hal with shape=(2640, 22) made from (2670, 8) and (11, 8)\n","Merged stock: ea with shape=(2644, 22) made from (2664, 8) and (11, 8)\n","Merged stock: m with shape=(2688, 22) made from (2708, 8) and (11, 8)\n","Merged stock: mcd with shape=(1592, 22) made from (1612, 8) and (11, 8)\n","Merged stock: mu with shape=(2222, 22) made from (2242, 8) and (11, 8)\n","Merged stock: gps with shape=(2642, 22) made from (2672, 8) and (11, 8)\n","Merged stock: ebay with shape=(2100, 22) made from (2120, 8) and (11, 8)\n","Merged stock: ko with shape=(2683, 22) made from (2703, 8) and (11, 8)\n","Merged stock: de with shape=(2651, 22) made from (2671, 8) and (11, 8)\n","Merged stock: fslr with shape=(2213, 22) made from (2233, 8) and (11, 8)\n","Merged stock: fdx with shape=(2625, 22) made from (2645, 8) and (11, 8)\n","Merged stock: vz with shape=(1972, 22) made from (1992, 8) and (11, 8)\n","Merged stock: dal with shape=(2646, 22) made from (2666, 8) and (11, 8)\n","Merged stock: jcp with shape=(1795, 22) made from (1815, 8) and (11, 8)\n","Merged stock: tsla with shape=(160, 22) made from (180, 8) and (11, 8)\n","Merged stock: low with shape=(2647, 22) made from (2667, 8) and (11, 8)\n","Merged stock: db with shape=(2649, 22) made from (2669, 8) and (11, 8)\n","Merged stock: qcom with shape=(2085, 22) made from (2105, 8) and (11, 8)\n","Merged stock: mdt with shape=(2651, 22) made from (2671, 8) and (11, 8)\n","Merged stock: agn with shape=(2646, 25) made from (2666, 8) and (11, 8)\n","Merged stock: orcl with shape=(2282, 22) made from (2302, 8) and (11, 8)\n","Merged stock: ma with shape=(2651, 22) made from (2671, 8) and (11, 8)\n","Merged stock: wfc with shape=(2053, 22) made from (2073, 8) and (11, 8)\n","Merged stock: hd with shape=(2649, 22) made from (2669, 8) and (11, 8)\n","Merged stock: bidu with shape=(2114, 22) made from (2134, 8) and (11, 8)\n","Merged stock: cat with shape=(2127, 22) made from (2157, 8) and (11, 8)\n","Finished merged dataset with shape: (115768, 25)\n"]},{"data":{"text/html":["\n","  <div id=\"df-6691406b-e20a-4e2b-9493-280ecbb5fe04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Volume</th>\n","      <th>label</th>\n","      <th>1daydiff</th>\n","      <th>2daydiff</th>\n","      <th>3daydiff</th>\n","      <th>4daydiff</th>\n","      <th>...</th>\n","      <th>spy2daydiff</th>\n","      <th>spy3daydiff</th>\n","      <th>spy4daydiff</th>\n","      <th>spy5daydiff</th>\n","      <th>spy10daydiff</th>\n","      <th>spy20daydiff</th>\n","      <th>spy30daydiff</th>\n","      <th>negative</th>\n","      <th>neutral</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.705000</td>\n","      <td>22.709999</td>\n","      <td>22.490000</td>\n","      <td>22.584999</td>\n","      <td>3000600.0</td>\n","      <td>0</td>\n","      <td>0.009160</td>\n","      <td>0.028695</td>\n","      <td>0.025193</td>\n","      <td>-0.009647</td>\n","      <td>...</td>\n","      <td>0.013855</td>\n","      <td>0.015765</td>\n","      <td>-0.007952</td>\n","      <td>-0.005482</td>\n","      <td>0.001799</td>\n","      <td>-0.065860</td>\n","      <td>-0.079769</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>22.700001</td>\n","      <td>22.700001</td>\n","      <td>22.315001</td>\n","      <td>22.475000</td>\n","      <td>3815200.0</td>\n","      <td>-1</td>\n","      <td>-0.004870</td>\n","      <td>0.004245</td>\n","      <td>0.023685</td>\n","      <td>0.020200</td>\n","      <td>...</td>\n","      <td>0.011111</td>\n","      <td>0.012771</td>\n","      <td>0.014676</td>\n","      <td>-0.008914</td>\n","      <td>0.005119</td>\n","      <td>-0.077043</td>\n","      <td>-0.088423</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>22.400000</td>\n","      <td>22.405001</td>\n","      <td>21.969999</td>\n","      <td>21.980000</td>\n","      <td>3416000.0</td>\n","      <td>-1</td>\n","      <td>-0.022025</td>\n","      <td>-0.026788</td>\n","      <td>-0.017873</td>\n","      <td>0.001139</td>\n","      <td>...</td>\n","      <td>0.001797</td>\n","      <td>0.013636</td>\n","      <td>0.015308</td>\n","      <td>0.017157</td>\n","      <td>0.005467</td>\n","      <td>-0.073614</td>\n","      <td>-0.076946</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>21.745001</td>\n","      <td>22.025000</td>\n","      <td>21.730000</td>\n","      <td>21.820000</td>\n","      <td>3321400.0</td>\n","      <td>1</td>\n","      <td>-0.007279</td>\n","      <td>-0.029144</td>\n","      <td>-0.033872</td>\n","      <td>-0.025022</td>\n","      <td>...</td>\n","      <td>0.000215</td>\n","      <td>-0.000759</td>\n","      <td>0.011001</td>\n","      <td>0.012616</td>\n","      <td>0.005123</td>\n","      <td>-0.057682</td>\n","      <td>-0.060973</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>22.000000</td>\n","      <td>22.230000</td>\n","      <td>21.920000</td>\n","      <td>22.105000</td>\n","      <td>3525800.0</td>\n","      <td>0</td>\n","      <td>0.013061</td>\n","      <td>0.005687</td>\n","      <td>-0.016463</td>\n","      <td>-0.021253</td>\n","      <td>...</td>\n","      <td>-0.004510</td>\n","      <td>-0.001594</td>\n","      <td>-0.002574</td>\n","      <td>0.009345</td>\n","      <td>-0.002955</td>\n","      <td>-0.046273</td>\n","      <td>-0.055337</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã 25 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6691406b-e20a-4e2b-9493-280ecbb5fe04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6691406b-e20a-4e2b-9493-280ecbb5fe04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6691406b-e20a-4e2b-9493-280ecbb5fe04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        Open       High        Low      Close     Volume  label  1daydiff  \\\n","0  22.705000  22.709999  22.490000  22.584999  3000600.0      0  0.009160   \n","1  22.700001  22.700001  22.315001  22.475000  3815200.0     -1 -0.004870   \n","2  22.400000  22.405001  21.969999  21.980000  3416000.0     -1 -0.022025   \n","3  21.745001  22.025000  21.730000  21.820000  3321400.0      1 -0.007279   \n","4  22.000000  22.230000  21.920000  22.105000  3525800.0      0  0.013061   \n","\n","   2daydiff  3daydiff  4daydiff  ...  spy2daydiff  spy3daydiff  spy4daydiff  \\\n","0  0.028695  0.025193 -0.009647  ...     0.013855     0.015765    -0.007952   \n","1  0.004245  0.023685  0.020200  ...     0.011111     0.012771     0.014676   \n","2 -0.026788 -0.017873  0.001139  ...     0.001797     0.013636     0.015308   \n","3 -0.029144 -0.033872 -0.025022  ...     0.000215    -0.000759     0.011001   \n","4  0.005687 -0.016463 -0.021253  ...    -0.004510    -0.001594    -0.002574   \n","\n","   spy5daydiff  spy10daydiff  spy20daydiff  spy30daydiff  negative  neutral  \\\n","0    -0.005482      0.001799     -0.065860     -0.079769       0.0      0.0   \n","1    -0.008914      0.005119     -0.077043     -0.088423       0.0      0.0   \n","2     0.017157      0.005467     -0.073614     -0.076946       0.0      0.0   \n","3     0.012616      0.005123     -0.057682     -0.060973       0.0      0.0   \n","4     0.009345     -0.002955     -0.046273     -0.055337       0.0      0.0   \n","\n","   positive  \n","0       0.0  \n","1       0.0  \n","2       0.0  \n","3       0.0  \n","4       0.0  \n","\n","[5 rows x 25 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["df = combine_datasets()\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"nkZotlMTI1iS"},"source":["# Split DF into train, val, test for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wI7LjSvEDgV"},"outputs":[],"source":["# Split combined DF into a 0.6, 0.2, 0.2 train, val, test split\n","def split_train_val_test(df):\n","\n","  # Splitting into training and temporary data with stratification and shuffling\n","  df_train, df_temp = train_test_split(df, test_size=0.4, stratify=df['label'], shuffle=True, random_state=42)\n","\n","  # Splitting the temporary data into validation and testing data with stratification and shuffling\n","  df_val, df_test = train_test_split(df_temp, test_size=0.5, stratify=df_temp['label'], shuffle=True, random_state=42)\n","\n","  # Split into x and labels\n","\n","  x_train = df_train.drop(columns=[\"label\"])\n","  y_train = df_train[\"label\"]\n","\n","  x_val = df_val.drop(columns=[\"label\"])\n","  y_val = df_val[\"label\"]\n","\n","  x_test = df_test.drop(columns=[\"label\"])\n","  y_test = df_test[\"label\"]\n","\n","  # Printing the shape of each DataFrame to verify the split\n","  print(\"Original DataFram shape:\", df.shape, \"\\n\")\n","\n","  print(\"x_train DataFrame shape:\", x_train.shape)\n","  print(\"y_train DataFrame shape:\", y_train.shape, \"\\n\")\n","\n","  print(\"x_val DataFrame shape:\", x_val.shape)\n","  print(\"y_val DataFrame shape:\", y_val.shape, \"\\n\")\n","\n","  print(\"x_test DataFrame shape:\", x_test.shape)\n","  print(\"y_test DataFrame shape:\", y_test.shape)\n","\n","\n","\n","\n","  return x_train, y_train, x_val, y_val, x_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686142016052,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"1iAQfL2zHdZ6","outputId":"f7eb06a5-63e1-4f73-92d3-a44696fd4b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original DataFram shape: (115768, 25) \n","\n","x_train DataFrame shape: (69460, 24)\n","y_train DataFrame shape: (69460,) \n","\n","x_val DataFrame shape: (23154, 24)\n","y_val DataFrame shape: (23154,) \n","\n","x_test DataFrame shape: (23154, 24)\n","y_test DataFrame shape: (23154,)\n"]}],"source":["x_train, y_train, x_val, y_val, x_test, y_test = split_train_val_test(df)"]},{"cell_type":"markdown","metadata":{"id":"E5ENXAu6ORal"},"source":["# Neural Network Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBs9g7i8ORDm"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686142019986,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"9PYOOXVySxl5","outputId":"6f27eaf7-49a0-4f82-aac4-a4e713651bb1"},"outputs":[{"data":{"text/plain":["( 1    24995\n"," -1    23266\n","  0    21199\n"," Name: label, dtype: int64,\n","  1    8332\n"," -1    7755\n","  0    7067\n"," Name: label, dtype: int64,\n","  1    8332\n"," -1    7756\n","  0    7066\n"," Name: label, dtype: int64)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts(), y_val.value_counts() , y_test.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"pIFsqD4cLCTA"},"source":["# Prepare DataFrames for training on Pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1686143620980,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"X2gZKYNLP0bS","outputId":"f5e5b09d-c711-4baa-bb82-c07353d10d4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Moved DFs to cuda:0 dataset tensors\n"]}],"source":["# Check for device (GPU preferred)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Create data tensors\n","x_train_tensor = torch.tensor(x_train.values).float().to(device)\n","x_val_tensor = torch.tensor(x_val.values).float().to(device)\n","x_test_tensor = torch.tensor(x_test.values).float().to(device)\n","\n","# Add +1 to ys to make them [0, 1, 2] instead of [-1, 0, 1] for training\n","y_train_tensor = (torch.tensor(y_train.values).float() + 1).to(device)\n","y_val_tensor = (torch.tensor(y_val.values).float() + 1).to(device)\n","y_test_tensor = (torch.tensor(y_test.values).float() + 1).to(device)\n","\n","# Create datasets\n","\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n","test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n","\n","\n","print(f\"Moved DFs to {train_dataset.tensors[0].device} dataset tensors\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1686143623791,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"ogDe7f0koaOl","outputId":"96bac011-afc9-446d-e4bf-cac9ba1e8dec"},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["x_train_tensor.device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBMnajGkOcNi"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self, hidden_size=20, n_hidden=2,):\n","        super(NeuralNetwork, self).__init__()\n","\n","        # Define the layers\n","        self.input_layer = nn.Linear(24, hidden_size)  # 24 input nodes, hidden_size hidden nodes\n","        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(n_hidden)])  # n_hidden  layers\n","        self.output_layer = nn.Linear(hidden_size, 3)  # hidden_size hidden nodes, 3 output nodes\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.input_layer(x))\n","\n","        for hidden_layer in self.hidden_layers:\n","            x = self.relu(hidden_layer(x))\n","\n","        x = self.output_layer(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"vqZLGTWVvMFA"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gd3ZREF70p6p"},"outputs":[],"source":["# Model Hyper Parameters\n","batch_size = 69460\n","num_epochs = 250\n","report_interval = 25\n","\n","learning_rates = [1e-4]\n","label_smoothing = [0.05]\n","n_hidden = [6]\n","hidden_size = [48]\n","\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3G-kMqny0q1L"},"outputs":[],"source":["def _train_loop(clf, optimizer, loss_fn):\n","  train_acc_list = []\n","  val_acc_list = []\n","  train_loss_list = []\n","  epoch_list = []\n","\n","  # Training loop\n","  for epoch in range(0, num_epochs+1):\n","      clf.train()\n","      running_loss = 0\n","\n","      for batch_data, batch_labels in train_loader:\n","        batch_data = batch_data.to(device)\n","        batch_labels = batch_labels.type(torch.LongTensor).to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        output = clf(batch_data).to(device)\n","\n","        # Compute the loss\n","        loss = loss_fn(output, batch_labels)\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update the weights\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","      # Report training and validation accuracy every 10 epochs\n","      if (epoch % report_interval == 0):\n","        clf.eval()  # Set the model to evaluation mode\n","\n","        train_c = 0\n","        train_t = len(train_dataset)\n","\n","        val_c = 0\n","        val_t = len(val_dataset)\n","\n","        with torch.no_grad(): # Turns off grad calculations for better performance\n","\n","\n","          # Compute Training Accuracy\n","          for batch_data, batch_labels in train_loader:\n","            batch_data = batch_data.to(device)\n","            batch_labels = batch_labels.type(torch.LongTensor).to(device)\n","\n","            output = clf(batch_data).to(device)\n","\n","            pred_labels = torch.argmax(output, dim=1).to(device)\n","            train_c += torch.sum(pred_labels == batch_labels).item()\n","\n","          # Compute validation accuracy\n","          for batch_data, batch_labels in val_loader:\n","            batch_data = batch_data.to(device)\n","            batch_labels = batch_labels.type(torch.LongTensor).to(device)\n","\n","            output = clf(batch_data).to(device)\n","\n","            pred_labels = torch.argmax(output, dim=1).to(device)\n","            val_c += torch.sum(pred_labels == batch_labels).item()\n","\n","        train_acc = (train_c / train_t)\n","        val_acc = (val_c / val_t)\n","        epoch_loss = running_loss / len(train_dataset)\n","        train_loss_list.append(epoch_loss)\n","        epoch_list.append(epoch)\n","\n","        # Print the accuracies\n","        print(f\"  Epoch {epoch}: train_loss: {round(epoch_loss, 7)} train_acc: { round(train_acc, 5)}, val_acc: {round(val_acc, 5)}\")\n","        train_acc_list.append(train_acc)\n","        val_acc_list.append(val_acc)\n","\n","  return train_acc_list, val_acc_list, train_loss_list, epoch_list, clf\n","\n","\n","\n","def train():\n","  best_model = None\n","  best_val_acc = 0.0\n","  best_val_list = []\n","  best_train_list = []\n","  best_train_loss = []\n","  for lr in learning_rates:\n","    for ls in label_smoothing:\n","      for nh in n_hidden:\n","        for hs in hidden_size:\n","          #  Instantiate a new nn model\n","          NNmodel_dev = NeuralNetwork(hidden_size=hs, n_hidden=nh).to(device)\n","\n","          # Define the loss function\n","          loss_fn = nn.CrossEntropyLoss(label_smoothing=ls).to(device)\n","\n","          # set optimizer with learning rate\n","          optimizer = optim.Adam(NNmodel_dev.parameters(), lr=lr)\n","          for state in optimizer.state.values():\n","            for k, v in state.items():\n","                state[k] = v.to(device)\n","\n","          # Train\n","          print(f\"Model: learn_rate={lr} label_smooth={ls} num_hidden={nh} hidden_size={hs}\")\n","          train_acc_list, val_acc_list, train_loss_list, epoch_list, clf = _train_loop(clf=NNmodel_dev, optimizer=optimizer, loss_fn=loss_fn)\n","          dic = {\"epochs\" : epoch_list, \"train acc\": train_acc_list, \"val acc\": val_acc_list, \"train loss\" : train_loss_list}\n","          df = pd.DataFrame(dic)\n","          df.to_csv(f\"./outputs/lr={lr}_ls={ls}_nh={nh}_hs={hs}.csv\", index=False)\n","\n","          if max(val_acc_list) > best_val_acc:\n","            best_val_acc = max(val_acc_list)\n","            best_val_list = val_acc_list\n","            best_train_list = train_acc_list\n","            best_train_loss = train_loss_list\n","            best_model = clf\n","  try:\n","    pickle_obj(best_model, \"best_nn_model\", overwrite=True)\n","  except:\n","    pass\n","\n","  return best_val_acc, best_val_list, best_train_list, best_train_loss, best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1686151200582,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"Klisu0zqcWsk","outputId":"7580b7e2-c82a-4724-abe2-4828db52c5f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ITqmE0bB295N","outputId":"0d8f5c83-92ab-4c82-e5e9-b85183d626ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: learn_rate=0.0001 label_smooth=0.05 num_hidden=6 hidden_size=48\n","  Epoch 0: train_loss: 0.0328378 train_acc: 0.33496, val_acc: 0.33497\n","  Epoch 25: train_loss: 0.001948 train_acc: 0.35985, val_acc: 0.35985\n","  Epoch 50: train_loss: 0.000186 train_acc: 0.33536, val_acc: 0.34137\n","  Epoch 75: train_loss: 0.0001338 train_acc: 0.33501, val_acc: 0.33497\n","  Epoch 100: train_loss: 2.56e-05 train_acc: 0.30438, val_acc: 0.30401\n","  Epoch 125: train_loss: 3.96e-05 train_acc: 0.33517, val_acc: 0.33493\n","  Epoch 150: train_loss: 0.0001083 train_acc: 0.33521, val_acc: 0.33467\n","  Epoch 175: train_loss: 5.81e-05 train_acc: 0.33593, val_acc: 0.33541\n","  Epoch 200: train_loss: 0.0001342 train_acc: 0.33514, val_acc: 0.33463\n","  Epoch 225: train_loss: 0.0002077 train_acc: 0.3052, val_acc: 0.30526\n","  Epoch 250: train_loss: 0.0001794 train_acc: 0.33496, val_acc: 0.33497\n","Overwriting '/content/drive/Shareddrives/cs145project/pickles/best_nn_model.pickle' object\n","pickling 'best_nn_model' model...done. Saved 'best_nn_model' model to /content/drive/Shareddrives/cs145project/pickles/best_nn_model.pickle\n"]}],"source":["best_val_acc, best_val_list, best_train_list, best_train_loss, best_model = train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1686154094157,"user":{"displayName":"Kia Afzali","userId":"12812182711337771987"},"user_tz":420},"id":"ev2CgLOfyRXM","outputId":"e1f0963f-fe90-49c9-e029-5101c4cceaf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  0.3369612162045435\n","Predicted Labels:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Correct   Labels:  [0, 1, 0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 2, 1, 2]\n"]}],"source":["# Test Accuracy\n","output = best_model(x_test_tensor)\n","pred_labels = torch.argmax(output, dim=1).to(device)\n","test_acc = (torch.sum(pred_labels == y_test_tensor).item()) / len(x_test_tensor)\n","print(\"Test accuracy: \", test_acc)\n","print(\"Predicted Labels: \", pred_labels[0:15].tolist())\n","print(\"Correct   Labels: \", [int(x) for x in y_test_tensor[0:15].tolist()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxVHE6uczCke"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxgOIcfZdCd1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","print(training_acc)\n","plt.plot(training_acc)\n","plt.plot(testing_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPt2ZaXDdnzc"},"outputs":[],"source":["print(NNmodel.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Go11ItO2gL2J"},"outputs":[],"source":["# print weights for first and last layer of NN\n","\n","for param in NNmodel.input_layer.parameters():\n","  print(\"Input Layer:\")\n","  if param.requires_grad:\n","    print(param[0])\n","\n","for param in NNmodel.output_layer.parameters():\n","  print(\"Output Layer:\")\n","  if param.requires_grad:\n","    print(param[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IvmqU_Gda6E"},"outputs":[],"source":["# print gradient for first and last layer of NN\n","\n","for param in NNmodel.input_layer.parameters():\n","  print(\"Input Layer:\")\n","  if param.requires_grad:\n","    print(param.grad[0])\n","\n","for param in NNmodel.output_layer.parameters():\n","  print(\"Output Layer:\")\n","  if param.requires_grad:\n","    print(param.grad[0])"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}